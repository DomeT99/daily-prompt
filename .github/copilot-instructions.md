# Daily Prompt - GitHub Copilot Instructions

## Project Overview
Daily Prompt is a curated collection of prompts designed to automate various processes across different Large Language Model (LLM) platforms. This repository serves as a centralized hub for organizing and sharing automation prompts, making it easier for developers and users to find and implement the right prompts for their specific language models and automation needs.

**Repository**: https://github.com/DomeT99/daily-prompt
**Created by**: DomeT99 (Domenico Tenace)

## Project Purpose & Goals

### Primary Objectives
- **Automation Focus**: Streamline various processes through well-crafted prompts
- **LLM Agnostic**: Support multiple language models with model-specific optimizations
- **Community Resource**: Provide a collaborative space for sharing effective prompts
- **Practical Application**: Deliver ready-to-use prompts with clear integration instructions

### Target Use Cases
- Process automation across different domains
- Workflow optimization using AI assistants
- Standardized prompt templates for common tasks
- Cross-platform LLM integration patterns

## Repository Structure & Organization

### Folder Organization
- **Model-Specific Folders**: Each major LLM (GPT-4, Claude, Gemini, etc.) has its own directory
- **Prompt Categories**: Organized by automation type and use case
- **Documentation**: Integration instructions and examples for each prompt
- **Metadata**: Prompt performance data and optimization notes

### File Conventions
- **Prompt Files**: Clear, descriptive naming convention
- **Documentation**: Accompanying explanation and usage examples
- **Version Control**: Track prompt iterations and improvements
- **Metadata**: Model compatibility, performance metrics, and use case tags

## Prompt Development Guidelines

### Writing Effective Prompts
- **Clarity**: Use clear, unambiguous language
- **Specificity**: Define exact requirements and expected outputs
- **Context**: Provide sufficient background information
- **Structure**: Organize prompts with clear sections and formatting
- **Testability**: Ensure prompts can be easily validated

### Model-Specific Considerations
- **GPT Series**: Leverage instruction-following capabilities
- **Claude**: Utilize constitutional AI principles and safety guidelines
- **Gemini**: Optimize for multimodal capabilities where applicable
- **Open Source Models**: Consider parameter limitations and training data

### Prompt Categories & Types

#### Process Automation
- Data processing and transformation
- Report generation and analysis
- Task scheduling and management
- Workflow orchestration

#### Content Creation
- Document generation templates
- Communication drafts and responses
- Creative writing assistants
- Technical documentation

#### Analysis & Decision Making
- Data analysis frameworks
- Risk assessment procedures
- Quality assurance checklists
- Performance evaluation criteria

#### Integration & API
- API interaction patterns
- Database query optimization
- System integration workflows
- Error handling procedures

## Documentation Standards

### Prompt Documentation Structure
```markdown
# Prompt Title
**Model Compatibility**: [List of compatible models]
**Use Case**: [Primary automation scenario]
**Difficulty Level**: [Beginner/Intermediate/Advanced]

## Description
[Clear explanation of what the prompt does]

## Usage Instructions
[Step-by-step implementation guide]

## Example Input/Output
[Concrete examples of prompt performance]

## Integration Notes
[Platform-specific integration details]

## Performance Metrics
[Accuracy, speed, resource usage data]
```

### Code Comments & Annotations
- Explain prompt logic and reasoning
- Document parameter variations and their effects
- Include troubleshooting common issues
- Reference related prompts and alternatives

## Quality Assurance & Testing

### Prompt Validation
- **Accuracy Testing**: Verify outputs meet specified requirements
- **Edge Case Handling**: Test with unusual or boundary inputs
- **Consistency**: Ensure reliable performance across multiple runs
- **Cross-Model Compatibility**: Validate performance across different LLMs

### Performance Optimization
- **Token Efficiency**: Minimize unnecessary tokens while maintaining clarity
- **Response Speed**: Optimize for faster generation times
- **Cost Effectiveness**: Balance performance with API costs
- **Scalability**: Ensure prompts work well at different volumes

## Integration Best Practices

### API Integration
- Include proper error handling patterns
- Implement rate limiting considerations
- Provide authentication and security guidelines
- Document API version compatibility

### Workflow Integration
- Design prompts for pipeline compatibility
- Consider data flow and transformation requirements
- Include logging and monitoring recommendations
- Provide rollback and failure recovery procedures

### Security Considerations
- Avoid including sensitive information in prompts
- Implement proper input sanitization
- Consider data privacy implications
- Include security validation checkpoints

## Contribution Guidelines

### Adding New Prompts
1. **Research Existing**: Check for similar prompts to avoid duplication
2. **Model Testing**: Validate across relevant LLM platforms
3. **Documentation**: Follow the standard documentation template
4. **Examples**: Provide clear, working examples
5. **Review Process**: Submit for community feedback

### Prompt Categories
- **Business Automation**: CRM, reporting, communication
- **Development**: Code review, documentation, testing
- **Content Management**: SEO, social media, marketing
- **Data Processing**: Analysis, transformation, validation
- **Customer Service**: Support responses, FAQ generation

### Versioning & Updates
- Track prompt iterations and improvements
- Maintain backward compatibility when possible
- Document breaking changes and migration paths
- Archive deprecated prompts with clear notices

## Automation Patterns & Templates

### Common Automation Patterns
- **Input Validation**: Structured data verification prompts
- **Batch Processing**: Handling multiple items efficiently
- **Error Recovery**: Graceful failure and retry mechanisms
- **Output Formatting**: Consistent response structures

### Template Variables
- Use standardized placeholder formats
- Provide clear variable documentation
- Include validation rules for inputs
- Support dynamic content injection

## Performance Monitoring

### Success Metrics
- **Accuracy Rate**: Correct outputs vs. total attempts
- **Processing Speed**: Average response time
- **User Satisfaction**: Feedback and adoption rates
- **Cost Efficiency**: Resource usage optimization

### Continuous Improvement
- Regular prompt performance reviews
- User feedback incorporation
- Model update compatibility testing
- Benchmark against newer techniques

## Community & Collaboration

### Knowledge Sharing
- Document lessons learned and best practices
- Share optimization techniques and discoveries
- Collaborate on complex automation challenges
- Provide mentorship for new contributors

### Open Source Principles
- Maintain transparency in prompt development
- Encourage community contributions and feedback
- Respect intellectual property and attribution
- Foster inclusive and collaborative environment

## Technical Considerations

### Model Limitations
- Understand token limits and context windows
- Consider model-specific strengths and weaknesses
- Plan for model updates and deprecations
- Implement fallback strategies

### Scalability Planning
- Design for high-volume usage scenarios
- Consider caching and optimization strategies
- Plan for concurrent usage patterns
- Monitor resource consumption and costs

## Notes for AI Assistant
- Focus on practical automation applications
- Prioritize clarity and usability in prompt design
- Consider cross-platform compatibility
- Maintain high documentation standards
- Emphasize testing and validation processes
- Support community-driven development approach
- Balance innovation with reliability and stability